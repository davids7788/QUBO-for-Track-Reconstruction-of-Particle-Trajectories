{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "809c2d2f",
   "metadata": {},
   "source": [
    "# Introduction to track reconstruction using quantum algorithms at LUXE\n",
    "\n",
    "This is an introduction about the concepts of track reconstruction at LUXE.\n",
    "This notebook will provide you with information and tasks to consolidate your knowledge.\n",
    "\n",
    "\n",
    "If something is unclear or if you just want to discuss something, don't forget: \n",
    "\n",
    "**We are always happy to answer your questions and to help you at any stage of the project!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad281fa",
   "metadata": {},
   "source": [
    "## Checklist before starting to work on this noteboook\n",
    "\n",
    "If you feel, that at least one of the following statements is not true, let's schedule a brief zoom meeting to make them true :)\n",
    "\n",
    "* I have knowledge about how charged particles are influenced by an magnetic field (bending raidus)\n",
    "* I have knowledge about the following python features:\n",
    "    - importing amd using (selfwritten) modules\n",
    "    - classes in python, in particular using and accessing functions and attributes/fields in classs\n",
    "    - plotting data with matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736deca9",
   "metadata": {},
   "source": [
    "##  I. Tracking data\n",
    "    a) LUXE positron tracking system\n",
    "    b) hits and tracks\n",
    "    c) file structure\n",
    "    d) load and process tracking data\n",
    "\n",
    "## II. Forming X-plets\n",
    "    a) a Combinatorial problem \n",
    "    b) doublets and triplets\n",
    "          - task 1: combinatorics\n",
    "    c) preselection at doublet level \n",
    "    d) creating doublets: an example\n",
    "          - task 2a) : preselection on doublet level - Finding dx/x0 and epsilon\n",
    "          - task 2b) : testing preselection parameters hypothesis\n",
    "          - task 2c) : finding a good angular condition - triplet preselection\n",
    "    e) creating triplets: an example\n",
    "\n",
    "## III. The (almost) real thing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7df5a9",
   "metadata": {},
   "source": [
    "## I. Tracking data\n",
    "### a) LUXE positron tracking system\n",
    "\n",
    "The LUXE electron-positron are created by shooting a powerful laser at the European XFEL 16.5 GeV electron beam. With a strong magnet these electron-positron pairs are separated and guiding to their respective tracking systems and calorimeters. \n",
    "\n",
    "In the following figure, the location of the positron tracking system is marked with the red arrow. The positron tracking system consists of :\n",
    "* 8 partly overlapping staves (green rectangles) and contain \n",
    "* 9 chips with 1024 x 512 pixels each and \n",
    "* a pixel size of 27$\\mu m$ x 29$\\mu m$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7f3590",
   "metadata": {},
   "source": [
    "<img src=\"img/Positron_Tracking_System.png\" width=600 height=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499924fe",
   "metadata": {},
   "source": [
    "For the track reconstruction task we start with a simplified simulation. With this tool we model the deflection of the positrons through the magnetic field and the interaction of the positrons with the detector layer (scattering e.g.). \n",
    "\n",
    "We are using a simplified simulation and not Geant4 (only at the moment) because we can tune and switch on/off these processes and also simplify the detector geometry to better understand the impact on the track reconstruction algorithm. \n",
    "\n",
    "The initial distribution and number of the positrons to use in our simplified simulation are taken from MC simulations with ptarmigan, which models what's hapening at the IP at LUXE. You do not need to understand what's happening in the frame of ptarmigan. But in case you are interested in this, you can have a look at https://arxiv.org/pdf/2108.10883.pdf.\n",
    "\n",
    "The output of the simplified simulation with the LUXE positron tracker geometry as it is (~10/2021) is displayed in the following figure. Hits on the detector layers are marked as red, whereas the green lines are drawn track examples.\n",
    "\n",
    "You may notice the darker shades of grey. These are actually very small gaps between the chips on each stave. These gaps would make track reconstruction a bit more challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79993e2",
   "metadata": {},
   "source": [
    "<img src=\"img/Luxe_FL.png\" width=600 height=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef048bb5",
   "metadata": {},
   "source": [
    "Overlapping + gaps between chips on the staves are the reasons why we are using a simplified geometry to make the track reconstruction task not unnessessarily complicated. We're aiming at getting knowledge about how to set parameters etc. of our track reconstruction algorithm at this simplier case. As soon if we're confident about our modelling, we will come back to the actual LUXE geometry.\n",
    "\n",
    "As a summary, in our simplified simulation:\n",
    "* we neglect that placing multiple chips on a stave results in small gaps between the chips\n",
    "* we assume that we have only four layers without any overlaps \n",
    "\n",
    "Then the output of the simplified simulation then changes to:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a692612",
   "metadata": {},
   "source": [
    "<img src=\"img/Luxe_SL.png\" width=600 height=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deafc58c",
   "metadata": {},
   "source": [
    "### b) Hits and tracks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46851324",
   "metadata": {},
   "source": [
    "Reading out the pixel information of a detector as \"1 activated pixel = 1 hit from a particle\" is unfortunately not correct. A particle can trigger more than one pixel, so before extracting the position information a hit-clustering has to be done. A nice example of how particles might create single and combined clusters is given in the following figure, taken from https://arxiv.org/pdf/1704.07983.pdf:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5408d61",
   "metadata": {},
   "source": [
    "<img src=\"img/Hit_Clusters.png\" width=600 height=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a35b459",
   "metadata": {},
   "source": [
    "We skip this clustering, because as a starting point we work with not digitized data. We assume that we have perfect knowledge about the hit coordinates of the particles on the detector.\n",
    "\n",
    "When combining hits from different detector layers a track can be formed. For the simplified geometry we define a track as\n",
    "\n",
    "**Four Hits From Consecutive Layers**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1133387",
   "metadata": {},
   "source": [
    "### c) File structure\n",
    "\n",
    "We have to save the information about the hits on the detector layer in a dedicated file format. A very easy and cross-platform accessible way is to use the .csv format.\n",
    "\n",
    "This is why we agreed on a data structure for the hits on the detector layer, inspired by the \"Track ML Challenge\" dataset, which is available on kaggle for example. See more at https://www.kaggle.com/competitions/trackml-particle-identification/.\n",
    "\n",
    "For every particle-detector interaction we save the following values:\n",
    "- **hit_ID**: A unique integer number across all hits on all detector layers within an event\n",
    "- **x**: x position of the hit in [m]\n",
    "- **y**: y position of the hit in [m]\n",
    "- **z**: z position of the hit in [m]\n",
    "- **layer**: detector layer identifier, they are labeled as Planes\n",
    "\n",
    "Also available are the following truth information, meaning simulation only:\n",
    "- **particle_ID**: integer number, identifying the particle which created the hit    \n",
    "- **particle_energy**: energy of the particle in [MeV]\n",
    "\n",
    "The \"tracking.csv\" file will look like this then:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4010417c",
   "metadata": {},
   "source": [
    "<img src=\"img/CSV_File_Example.png\" width=600 height=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74abd509",
   "metadata": {},
   "source": [
    "The file shown above has ~40000 entries, which correspond to ~10000 particles, because each particle will interact with each of the detector layers one time. Particles that are leaving the detector range due to multiple scattering will produce less than four entries in the .csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81786225",
   "metadata": {},
   "source": [
    "### d) Load and process tracking data\n",
    "\n",
    "As an example, we prepared a file with just 3 particles, to show how we process these data. We will only use 'hit_ID', 'layer', 'x', 'y' and 'z' for creating track candidates. Information on 'particle_ID' is only used for performance measurements, since this is an simulation exclusive value.\n",
    "\n",
    "A smart way to read in the tracking data from file is to use pandas. It is very good a grouping, slicing and presenting tabular data. \n",
    "For very big data sets it is better to use the csv module of python, because the many and nice features of pandas come with a higher cost in computational time and memory. Two examples are given in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff79da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccf4549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data with pandas\n",
    "tracking_data = pd.read_csv(\"examples/ExampleTrackingData.txt\")\n",
    "print(tracking_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45d83ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data with csv and context manager\n",
    "\n",
    "csv_data = []\n",
    "with open(\"examples/ExampleTrackingData.txt\") as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    csv_header = next(csv_reader)                # access header, csv files should consist of one line of header\n",
    "    for row in csv_reader:                       # iterate over all rows in the csv file\n",
    "        csv_data.append(row)\n",
    "\n",
    "print(csv_header)\n",
    "for data in csv_data:\n",
    "    print(data)\n",
    "    \n",
    "\n",
    "# The '' signs are indicating that the values are strings.\n",
    "# To work with this data one has to convert the strings for x,y and z later! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c32bf78",
   "metadata": {},
   "source": [
    "## II. Forming X-plets\n",
    "### a) A Combinatorial problem \n",
    "\n",
    "The term \"x-plets\" stands for a set of connected hits on different, consecutive detector layers. X-plets are basically parts of track candidates. Our goal is to find an optimal way of constructing and connecting x-plets to tracks with respect to some objective function.\n",
    "\n",
    "Let's first let's have a look at combinatorics:\n",
    "In the following figure a graphical representation of the example file from before is given. Asumming 3 particles and 4 layers we will end up with 12 hits. These hits are represented by the red dots. Our beam/forward direction is the z-axis. For now we stick to a 2D-representation of the example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdeef60",
   "metadata": {},
   "source": [
    "<img src=\"img/Raw_Hits_Detector.png\" width=600 height=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9986e6f",
   "metadata": {},
   "source": [
    "### b) Doublets and Triplets\n",
    "\n",
    "We start with a very basic assumption and state that \n",
    "\n",
    "**Two hits of the same detector layer cannot form an x-plet**.\n",
    "\n",
    "Also it is: \n",
    "\n",
    "**Forbidden to \"jump\" over a detector layer in the process of creating doublets and triplets**. \n",
    "\n",
    "So, for example a doublet from hits of detector layer 1 and 3 is not allowed. \n",
    "We also define, that a\n",
    "\n",
    "- **Doublet** is a set of two hits of consecutive layers.\n",
    "- **Triplet** is a set of two doublets with exactly one shared hit \n",
    "- **Track Candidate** is a set of two triplets with exactly two shared hits on the two middle layers\n",
    "\n",
    "Example how forming doublets, triplets and and track candidates could look like:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea0a09f",
   "metadata": {},
   "source": [
    "<img src=\"img/Doublet_Triplet_Track.png\" width=600 height=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70062e24",
   "metadata": {},
   "source": [
    "### Task I: Combinatorics\n",
    "\n",
    "Please consider the example above and answer the following questions and derive an equation with respect to the number of involved particles:\n",
    "- How many doublets can be created?\n",
    "- How many triplets can be created?\n",
    "- How many track candidates can be created?\n",
    "- We expect up to 1 Million positrons at LUXE. How many doublets, triplets and track candidates would we have to create?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e28b4f",
   "metadata": {},
   "source": [
    "### c) Preselection at doublet level\n",
    "\n",
    "A brute force approach is computational not feasible for a high number of particles. That's why we need to create doublets and triplets in a smart way. So let's have a look at the physics first:\n",
    "\n",
    "Within the detector area there is no magnetic field. But the tracks of the positrons are bent before by a dipole magnet.\n",
    "That means that tracks from positrons will form an angle with the beamaxis z with respect to their initial energy. A possible scenario could look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f334ca",
   "metadata": {},
   "source": [
    "<img src=\"img/Energy_Selection.png\" width=600 height=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cf7055",
   "metadata": {},
   "source": [
    "For a particle of mass **m**, Energy **E** and momentum **p** in a uniform B-field, the bending radius of the motion of the particle **inside the dipole field** is given by:\n",
    "\n",
    "$\\frac{1}{\\rho}= \\frac{e\\cdot B}{p \\cdot c} = \\frac{e\\cdot B}{\\beta E} $\n",
    "\n",
    "This means, that a higher energy will lead to less bending, and a higher magnetic field strength will bend the particle trajectory more. For our experimental setup we can conclude, that - in general - hits with a **higher x value** on the first detector layer have a **lower energy**, due to more bending of the particle trajectory. \n",
    "\n",
    "We now want to look for a connection between hits of one particle. Recalling the figure above one can find two assumptions: \n",
    "\n",
    "- The difference in x-values between **two consecutive hits** on different detector layers of **the same particle** decreases with the particle energy\n",
    "- Hits on the first detector layer with a **lower x value** have a **higher energy**\n",
    "\n",
    "Not all doublets which can be created from the hits have a hit on the first detector. But we want to include information about where this doublet - which is a part of track - would have a hit on the first detector layer. \n",
    "\n",
    "We model the information about the actual hit on the first detector layer - if a doublet was created from layer 1 -> 2 or an expected hit - if the doublet has no hit on detector layer 1 -  on the first detector layer from extrapolation into the modelling of our equation. We name the x-value on the first detector layer \"x0\".\n",
    "\n",
    "Every doublet that is worth considering for a piece of a track has to then to fulfill the equation:\n",
    "\n",
    "$\\frac{dx}{x_0} \\approx c = const$\n",
    "\n",
    "with $dx= x_2 - x_1$ and $x_0$ as shown in the following figure:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d552b7df",
   "metadata": {},
   "source": [
    "<img src=\"img/dx_x0_criteria.png\" width=600 height=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b417a3",
   "metadata": {},
   "source": [
    "In an ideal case $\\frac{dx}{x_0}$ would be very close to a constant value. But, there is also scattering, so the final equation needs to point at an interval and not a value:\n",
    "\n",
    "$\\frac{dx}{x_0} \\in [c - \\epsilon, c + \\epsilon]$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac8aa53",
   "metadata": {},
   "source": [
    "### c) creating doublets: an example\n",
    "\n",
    "Now we want to give you an example on how this is actually done, when we are using it for our needs.\n",
    "To handle our doublets as an object, we wrote a class named Doublet. \n",
    "A doublet object hast 6 attributes:\n",
    "- **hit_1_particle_key**: $\\hspace{0.09cm}$ the particle ID of the first hit, given by the \"particle_ID\" information in the .csv file\n",
    "- **hit_1_position**: $\\hspace{0.8cm}$ the particle position of the first hit as an array [x, y, z], given by the \"x\", \"y\" and \"z\" information in the .csv file\n",
    "- **hit_2_particle_key**: $\\hspace{0.09cm}$ the particle ID of the second hit, given by the \"particle_ID\" information in the .csv file\n",
    "- **hit_2_position**: $\\hspace{0.8cm}$ the particle position of the second hit as an array [x, y, z], given by the \"x\", \"y\" and \"z\" information in the .csv file\n",
    "- **hit_1_id**: $\\hspace{1.9cm}$ the hit ID of the first hit, given by the \"hit_ID\" information in the .csv file\n",
    "- **hit_2_id**: $\\hspace{1.9cm}$ the hit ID the second hit, given by the \"hit_ID\" information in the .csv file\n",
    "\n",
    "To use the class we first have to import it of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1238c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from doublet import Doublet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c67b859",
   "metadata": {},
   "source": [
    "For creating a doublet, you just have to provide the parameters given above. Every information you need is stored inside the .csv file. You just need to take care of the variable types since they are all strings! An example is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d738d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = float('1.0')          # x = '1.0' in .csv file. y, z accordingly \n",
    "y1 = float('3.0')\n",
    "z1 = float('1.0')\n",
    "\n",
    "x2 = float('2.0')\n",
    "y2 = float('4.0')\n",
    "z2 = float('1.0')\n",
    "\n",
    "particle_id_1 = \"1\"        # no adjustment needed for particle and hit id\n",
    "particle_id_2 = \"2\"\n",
    "\n",
    "hit_id_1 = \"5678\"\n",
    "hit_id_2 = \"8765\"\n",
    "\n",
    "\n",
    "test_doublet = Doublet(particle_id_1,\n",
    "                       [x1, y1, z1],\n",
    "                       particle_id_2,\n",
    "                       [x2, y2, z2],\n",
    "                       hit_id_1,\n",
    "                       hit_id_2)\n",
    "print(test_doublet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422ae424",
   "metadata": {},
   "source": [
    "Now we can encode our data from the .csv file into doublets.\n",
    "\n",
    "First we order the data with respect to the z-value of the hits, meaining we order them by layer.\n",
    "We know, that the detector layers have z-values of 0.0, 1.0, 2.0 and 3.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1313e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall what the data set looked like. \n",
    "csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b26c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entry[3] is the z-value of the hits. We're doing this sorting taks with list comprehension\n",
    "csv_data_detector_layer_0 = [entry for entry in csv_data if entry[3] == '0.0']\n",
    "csv_data_detector_layer_1 = [entry for entry in csv_data if entry[3] == '1.0']\n",
    "csv_data_detector_layer_2 = [entry for entry in csv_data if entry[3] == '2.0']\n",
    "csv_data_detector_layer_3 = [entry for entry in csv_data if entry[3] == '3.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6bd0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if lists now only contain data from one layer. If only entries with 'Plane 0' for csv_data_detector_layer_0 \n",
    "# what we did has worked\n",
    "csv_data_detector_layer_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c73114f",
   "metadata": {},
   "source": [
    "Now we can create the doublets. There will be 3 lists of doublets:\n",
    "- doublet_list01: hits on detector layer 0 connected with hits on detector layer 1\n",
    "- doublet_list12: hits on detector layer 1 connected with hits on detector layer 2\n",
    "- doublet_list23: hits on detector layer 2 connected hits hits on detector layer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f787cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define empty lists \n",
    "doublet_list01 = []\n",
    "doublet_list12 = []\n",
    "doublet_list23 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4066ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hit[0]: hit_ID \n",
    "# hit[1]: x \n",
    "# hit[2]: y \n",
    "# hit[3]: z \n",
    "# hit[5]: particle_ID    \n",
    "# need to convert strings for x, y and z to float for later calculations\n",
    "# Filling the lists:\n",
    "for hit_1 in csv_data_detector_layer_0:        # loop over first detector layer\n",
    "    for hit_2 in csv_data_detector_layer_1:    # loop over second detector layer\n",
    "        doublet_list01.append(Doublet(hit_1[5],                                            # particle ID first hit\n",
    "                                      [float(hit_1[1]), float(hit_1[2]), float(hit_1[3])], # [x, y, z] first hit\n",
    "                                      hit_2[5],                                            # particle ID second hit\n",
    "                                      [float(hit_2[1]), float(hit_2[2]), float(hit_2[3])], # [x, y, z] second hit\n",
    "                                      hit_1[0],                                            # hit ID first hit\n",
    "                                      hit_2[0]))                                           # hit ID second hit\n",
    "for hit_1 in csv_data_detector_layer_1:        # loop over second detector layer\n",
    "    for hit_2 in csv_data_detector_layer_2:    # loop over third detector layer\n",
    "        doublet_list12.append(Doublet(hit_1[5],                                            # particle ID first hit\n",
    "                                      [float(hit_1[1]), float(hit_1[2]), float(hit_1[3])], # [x, y, z] first hit\n",
    "                                      hit_2[5],                                            # particle ID second hit\n",
    "                                      [float(hit_2[1]), float(hit_2[2]), float(hit_2[3])], # [x, y, z] second hit\n",
    "                                      hit_1[0],                                            # hit ID first hit\n",
    "                                      hit_2[0]))   \n",
    "for hit_1 in csv_data_detector_layer_2:        # loop over third detector layer\n",
    "    for hit_2 in csv_data_detector_layer_3:    # loop over foruth detector layer\n",
    "        doublet_list23.append(Doublet(hit_1[5],                                            # particle ID first hit\n",
    "                                      [float(hit_1[1]), float(hit_1[2]), float(hit_1[3])], # [x, y, z] first hit\n",
    "                                      hit_2[5],                                            # particle ID second hit\n",
    "                                      [float(hit_2[1]), float(hit_2[2]), float(hit_2[3])], # [x, y, z] second hit\n",
    "                                      hit_1[0],                                            # hit ID first hit\n",
    "                                      hit_2[0]))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cb3e05",
   "metadata": {},
   "source": [
    "### Task 2a) : Preselection on doublet level - Finding dx/x0 and epsilon\n",
    "\n",
    "Please make some plots of the distributions of $\\frac{dx}{x_0}$ for all doublets.\n",
    "For every doublet d in the list you can access the coordinates [x,y,z] by calling:\n",
    "\n",
    "    d.hit_2_position and d.hit_1_position\n",
    "\n",
    "You will get the value $x_0$ at agiven z by calling:\n",
    "    \n",
    "    d.x0_at_z(x_2, x1, z2, z1, z0)\n",
    "    \n",
    "You can also check if the doublet is stemming from one single particle by calling:\n",
    "\n",
    "    d.is_correct_match\n",
    "\n",
    "Can you find an interval where only correct doublets(passing d.is_correct_match) are located?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f624e8b",
   "metadata": {},
   "source": [
    "### Task 2b) : Testing preselection parameters hypothesis\n",
    "\n",
    "In the following cell you have to choose the correct parameters for dx_x0 and dx_x0_epsilon to skim the list of (mostly unnessarily created) doublets. \n",
    "- If you already identified a good interval in the task before, then set the values accordingly. Be careful to keep all the correct ones! If you end up with 3 correct triplets and 3 or 4 kept doublets for each of the doublet lists, then you did well!\n",
    "\n",
    "- Could you find an intervall which works for all the lists? Is it possible to get rid of all fake doublets by this procedure? What effect is limiting this preselection procedure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7609b343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set values (--> task 2b)  \n",
    "dx_x0 = 0.0\n",
    "dx_x0_epsilon = 7\n",
    "\n",
    "# this one is fixed for our example, don't touch it please!\n",
    "z_reference = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969bd5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new list and save the doublets into this list if they pass the check\n",
    "\n",
    "doublet_list01_skimmed = []\n",
    "doublet_list12_skimmed = []\n",
    "doublet_list23_skimmed = []\n",
    "\n",
    "for doublet in doublet_list01:\n",
    "    if doublet.dx_x0_check(dx_x0, dx_x0_epsilon, z_reference):   # if check passes, doublet is appended to the skimmed list\n",
    "        doublet_list01_skimmed.append(doublet)  \n",
    "for doublet in doublet_list12:\n",
    "    if doublet.dx_x0_check(dx_x0, dx_x0_epsilon, z_reference):   # if check passes, doublet is appended to the skimmed list\n",
    "        doublet_list12_skimmed.append(doublet)\n",
    "for doublet in doublet_list23:\n",
    "    if doublet.dx_x0_check(dx_x0, dx_x0_epsilon, z_reference):   # if check passes, doublet is appended to the skimmed list\n",
    "        doublet_list23_skimmed.append(doublet) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7ac836",
   "metadata": {},
   "source": [
    "Let's check if it has worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571a4e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we evaluate the brute-force method\n",
    "correct_kept_doublets_bf = 0\n",
    "wrong_kept_doublets_bf = 0\n",
    "\n",
    "for d in doublet_list01:\n",
    "    if d.is_correct_match:\n",
    "        correct_kept_doublets_bf += 1\n",
    "    else:\n",
    "        wrong_kept_doublets_bf += 1\n",
    "\n",
    "print(\"Brute-Force creation of all doublets\")\n",
    "print(f\"Number of correct doublets: {correct_kept_doublets_bf}\")\n",
    "print(f\"Number of all doublets: {correct_kept_doublets_bf + wrong_kept_doublets_bf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a02e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we evaluate the skimmed list with our dx_x0 criteria applied\n",
    "correct_kept_doublets = 0\n",
    "wrong_kept_doublets = 0\n",
    "\n",
    "for d in doublet_list01_skimmed:\n",
    "    if d.is_correct_match:\n",
    "        correct_kept_doublets += 1\n",
    "    else:\n",
    "        wrong_kept_doublets += 1\n",
    "print(\"After removing unlikely combinations:\")\n",
    "print(f\"Number of correct doublets: {correct_kept_doublets}\")\n",
    "print(f\"Number of all doublets: {correct_kept_doublets + wrong_kept_doublets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a5c903",
   "metadata": {},
   "source": [
    "### e) creating triplets: an example\n",
    "\n",
    "Creating triplets out of doublets is much easier than creating doublets from hits. There are only two rules:\n",
    "- a triplet consists of two connected doublets with one shared hit\n",
    "- the angle in xz or yz is limited by some value\n",
    "\n",
    "So creating triplet means, you loop over doublet lists and combine them if they are compatible. Therefore we need the triplet class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71909621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from triplet import Triplet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3295a110",
   "metadata": {},
   "source": [
    "The triplet object consists of:\n",
    "\n",
    "- **doublet_1**: a before created doublet \n",
    "- **doublet_2**: another before created doublet\n",
    "- **triplet_id**: some unique identifyer, string or integer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225dc60a",
   "metadata": {},
   "source": [
    "### Task 2c) : Finding a good angular condition  - triplet preselection\n",
    "\n",
    "The triplet class already provides you with a function to check how big the angle difference in xz and yz is.\n",
    "you can do this by calling\n",
    "\n",
    "    t.angles_between_doublets()\n",
    "It returns [xz_angle, yz_angle] with xz_angle and yz_angle in rad.\n",
    "\n",
    "Again, you can check with\n",
    "\n",
    "    t.is_correct_match\n",
    "    \n",
    "if a triplet is stemming from one particle (correct match)\n",
    "\n",
    "Please make a plot of the angle distributions of xz and find a good cut value. You can choose the value in the cell below to select the correct triplets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef1a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating triplets from the first two doublet lists. We're now not adding the triplets to list if the\n",
    "# cut value does not apply:\n",
    "angular_condition_for_triplet_creation = 1.4\n",
    "\n",
    "triplet_list_012 = []\n",
    "id_counter = 0    # for giving the triplets a name\n",
    "for doublet_1 in doublet_list01:                                                              # loop over doublet list 01\n",
    "    for doublet_2 in doublet_list12:                                                          # loop over doublet list 12\n",
    "        if doublet_1.hit_2_position == doublet_2.hit_1_position:                              # check if shared hit\n",
    "            \n",
    "            t = Triplet(doublet_1, \n",
    "                        doublet_2, \n",
    "                        id_counter)                                     # create triplet object\n",
    "            \n",
    "            if abs(t.angles_between_doublets()[0]) <  angular_condition_for_triplet_creation:       \n",
    "                triplet_list_012.append(t)\n",
    "        id_counter += 1 \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42da6a3d",
   "metadata": {},
   "source": [
    "Let's check the performance of your selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7986ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we evaluate the skimmed list with our dx_x0 criteria applied\n",
    "correct_kept_triplets = 0\n",
    "wrong_kept_triplets = 0\n",
    "\n",
    "for t in triplet_list_012:\n",
    "    if t.is_correct_match:\n",
    "        correct_kept_triplets += 1\n",
    "    else:\n",
    "        wrong_kept_triplets += 1\n",
    "print(\"After removing unlikely combinations:\")\n",
    "print(f\"Number of correct triplets: {correct_kept_triplets}\")\n",
    "print(f\"Number of all triplets: {correct_kept_triplets + wrong_kept_triplets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a193891",
   "metadata": {},
   "source": [
    "Great! We now have our triplets!\n",
    "\n",
    "We use information which is storred inside the triplet objects for the quantum computing part of our track reconstruction. \n",
    "\n",
    "Many of the created triplets are \"fake tracks\" or at least parts of fake tracks. That means, that the detector hits which are stored inside the triplets, are not from the same particle. Since we do not have this truth knowledge for real data, we need an algorithm which tells us which triplets to keep and which to discard. And that's exactly where the quantum computing part is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac7fc38",
   "metadata": {},
   "source": [
    "## Checklist after finishing this noteboook\n",
    "\n",
    "If you feel, that at least one of the following statements is not true, let's schedule a meeting to make them true :)\n",
    "\n",
    "* I have a good overview about the LUXE positron detection system geometry\n",
    "* I know how I can access the tracking data files, load, inspect and process them\n",
    "* I am familiar with the concept of grouping hits to x-plets\n",
    "* I know why it is important to start with a preselection instead of a brute force approach\n",
    "* I can use the doublet and triplet class and create doublets and triplets from the given data\n",
    "* I can identify the parameters for a successful preselection and perform it also"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f1fd50",
   "metadata": {},
   "source": [
    "# III. The (almost) real thing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db8b900",
   "metadata": {},
   "source": [
    "There's another file in the *examples/* folder. It contains data from our Simplified Simulation. Can you find a best preselection for it?\n",
    "If you accept the challenge, please measure your results in:\n",
    "\n",
    "* Number of participating particles / (0.5 * kept correct triplets)\n",
    "\n",
    "which is some kind of preselection efficiency. Maybe you can also come up with your own idea to improve the preselection!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
